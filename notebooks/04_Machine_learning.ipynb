{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part IV: Machine learning\n",
    "\n",
    "![](img/machine_learning.png)\n",
    "\n",
    "In this section we'll learn:\n",
    "\n",
    "- Regression models\n",
    "- Classification models\n",
    "- Measuring model errors\n",
    "- The [scikit-learn](http://scikit-learn.org/) API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "movies = pandas.read_json('data/movies_clean.jsonl.bz2', lines=True).set_index('imdb_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In supervised machine learning, the goal is to make a prediction. In this case we will try to predict the rating that a movie will get, based in other available data.\n",
    "\n",
    "Most machine learning models, like `logistic regression`, `random forest` and even `deep learning` models require that all the data is numerical, and that no missing data exists.\n",
    "\n",
    "So, preprocessing is usually required in this sense. How this can be done? This depends of ourselves, about the available data, our business knowledge, and about how we master the *art* of machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Let us start with the title. What information can we obtain from it? Advanced techniques on natural language processing will be seen in the next section. But so far there are two \"obvious\" features that we can extract from it:\n",
    "- The number of words\n",
    "- The number of characters\n",
    "\n",
    "Whether these are features that are relevant to estimate the rating of a movie we don't know. We can guess that they won't be the most relevant, but considering them should not harm (that may not be true, for a phenomena named the *curse of dimensionality*).\n",
    "\n",
    "**Exercise:** We will keep the features we extract in a separate `DataFrame` named `data`. This is not necessary, but should make it easier to see which features are \"ready\". Add to this `DataFrame` the features with the number of words and characters in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = movies[['num_ratings', 'rate']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next feature to consider is `color`. In our data, the color can only be two values, `Color` or `Black and White`. So, even if the feature is a text, we can easily convert to a boolean value, on whether the value is one of them.\n",
    "\n",
    "**Exercise:** Create a column `is_color` in `data`. In Python, `True == 1` and `False == 0`, so a boolean column is fine (or it can also be transformed to another numerical type like `int` or `float`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The release date can also contain relevant information, even if as a date, it can't be directly processed. Some numerical information that can be extracted from a date:\n",
    "- The days or years since the release of the movie (how old is it)\n",
    "- The month of the release (are the best movies released in specific months?)\n",
    "- The day of the week (probably not important, but who knows)\n",
    "\n",
    "**Exercises:**\n",
    "- Think what happened to the `release_date` that we extracted in the first section. Can you guess?\n",
    "- Fix the problem. Can we use `pandas.to_datetime()` again? Is the `unit` parameter relevant?\n",
    "- Extract the features mentioned above, and any other that you think can be relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will consider the genres. In this case we will use a technique named `one hot encoding` (aka `dummy variables`). It consists in creating a column for each possible value (e.g. `Romance`, `Action`, `Comedy`...) and set a value `0` or `1` depending on whether the row contains that value.\n",
    "\n",
    "`pandas` contains two functions to extract the `dummy features`. The most commonly used  is `pandas.get_dummies` which converts a string `Series` into the dummies `DataFrame`. In case one row can have more than one value (like genres in our case) we can use `Series.str.get_dummies()`, which expects a string where the values are separated by a delimiter.\n",
    "\n",
    "**Exercises:**\n",
    "- Convert the content of `genres` from a `list` to a string separated by a delimiter of your choice. You can use the method `.apply()` to apply an arbitrary Python function to all the values of a `Series` at a time. \n",
    "- Get the dummy variables and add them to our `data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we start using machine learning, we will split our dataset in two. The response feature we want to predict, and all the explanatory features.\n",
    "\n",
    "**Exercise:** Create a `DataFrame` named `x` with all the columns except the rating, and a `Series` named `y` for the rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` uses `numpy` arrays of `float` in most cases. We can usually provide the data in `pandas` containers of any type, and will do the conversions automatically. But let us do it explicitly.\n",
    "\n",
    "**Exercise:** Convert `x` and `y` to `numpy` arrays of type `float`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`scikit-learn` works with pipelines. Those pipelines are a set of transformations to the data and the final predictive model saved in a single object. The goal is for this object to remember required information to transform the data at the prediction time.\n",
    "\n",
    "For example, if we want to scale the data (this is important for some models) we need to remember from the training to the prediction time, the `mean` used to scale the data. This is saved and kept in the pipeline.\n",
    "\n",
    "To create a pipeline the simpler option is to use `sklearn.pipeline.make_pipeline` and provide each one of the steps.\n",
    "\n",
    "**Exercise:** Create a pipeline with the next objects:\n",
    "- `sklearn.preprocessing.Imputer`\n",
    "- `sklearn.preprocessing.StandardScaler`\n",
    "- `sklearn.linear_model.LinearRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train our model (make it learn how to predict based on our data), we use the method `.fit(x, y)`. Then, to make predictions, we use the method `.predict(x)`.\n",
    "\n",
    "**Exercises:**\n",
    "- Train the model built in the previous step, with the data we obtained.\n",
    "- Make predictions for the same data.\n",
    "- Convert the predictions to a `pandas.Series` and compare them with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
